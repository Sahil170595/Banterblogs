{ "generated_at": "2025-10-03T03:19:06.069710+00:00", "model": { "name": "transformer", "device": "cuda", "dtype": "torch.float32", "batch_size": 2, "seq_len": 128, "embed_dim": 256, "num_heads": 4, "num_layers": 2 }, "settings": { "runs": 5, "warmup_runs": 2, "backends": [ "eager", "jit", "torch_compile", "onnx", "tensorrt" ] }, "backends": { "eager": { "backend": "eager", "compilation": null, "benchmark": { "backend": "eager", "mean_time_ms": 0.6845500000054017, "std_time_ms": 0.06047175455820866, "min_time_ms": 0.6295679995673709, "max_time_ms": 0.800318000074185, "metadata": { "compile_time_s": 0.0 } } }, "jit": { "backend": "jit", "compilation": { "backend": "torchscript", "success": true, "compile_time_s": 0.12024033200032136, "metadata": { "strict": false, "frozen": true, "graph_preview": [ "graph(%self.1 : __torch__.___torch_mangle_39.TinyTransformer,", " %x : Tensor):", " %10 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.layers.0", " %9 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %8 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %7 : int = prim::Constant[value=4](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %6 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %self.head.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.head.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_weight : Float(768, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_bias : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.weight : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.weight : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.bias : Float(1024, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.weight : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %src : Tensor = aten::_transformer_encoder_layer_fwd(%x, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %input : Tensor = aten::_transformer_encoder_layer_fwd(%src, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.1 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0" ] }, "error": null }, "benchmark": { "backend": "jit", "mean_time_ms": 0.346948999685992, "std_time_ms": 0.03996218431009646, "min_time_ms": 0.2852549996532616, "max_time_ms": 0.40331999935006024, "metadata": { "compile_time_s": 0.12024033200032136, "strict": false, "frozen": true, "graph_preview": [ "graph(%self.1 : __torch__.___torch_mangle_39.TinyTransformer,", " %x : Tensor):", " %10 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.layers.0", " %9 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %8 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %7 : int = prim::Constant[value=4](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %6 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %self.head.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.head.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_weight : Float(768, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_bias : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.weight : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.weight : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.bias : Float(1024, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.weight : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %src : Tensor = aten::_transformer_encoder_layer_fwd(%x, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %input : Tensor = aten::_transformer_encoder_layer_fwd(%src, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.1 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0" ] } } }, "torch_compile": { "backend": "torch_compile", "compilation": { "backend": "torch.compile", "success": true, "compile_time_s": 1.5707857389998026, "metadata": { "backend": "inductor", "mode": "default", "fullgraph": false, "dynamic": false }, "error": null }, "benchmark": { "backend": "torch_compile", "mean_time_ms": 0.4805684000530164, "std_time_ms": 0.08942686208929052, "min_time_ms": 0.4008530004284694, "max_time_ms": 0.6446059996960685, "metadata": { "compile_time_s": 1.5707857389998026, "backend": "inductor", "mode": "default", "fullgraph": false, "dynamic": false } } }, "onnx": { "backend": "onnx", "compilation": { "backend": "onnx", "success": true, "compile_time_s": 0.2336820450000232, "metadata": { "onnx_path": "/tmp/chimera_onnx__p4itfkf/model.onnx", "opset": 17, "providers": [ "CPUExecutionProvider" ], "session_type": "onnxruntime" }, "error": null }, "benchmark": { "backend": "onnx", "mean_time_ms": 4.0951231998406, "std_time_ms": 0.10541497269324254, "min_time_ms": 3.9222040004460723, "max_time_ms": 4.214468999634846, "metadata": { "compile_time_s": 0.2336820450000232, "onnx_path": "/tmp/chimera_onnx__p4itfkf/model.onnx", "opset": 17, "providers": [ "CPUExecutionProvider" ], "session_type": "onnxruntime" } } }, "tensorrt": { "backend": "tensorrt", "compilation": { "backend": "tensorrt", "success": false, "compile_time_s": null, "metadata": { "suggestion": "pip install torch-tensorrt -f https://github.com/pytorch/TensorRT/releases" }, "error": "torch_tensorrt is not installed" }, "benchmark": { "backend": "tensorrt", "mean_time_ms": 0.0, "std_time_ms": 0.0, "min_time_ms": 0.0, "max_time_ms": 0.0, "metadata": { "error": "torch_tensorrt is not installed" } } } }
}