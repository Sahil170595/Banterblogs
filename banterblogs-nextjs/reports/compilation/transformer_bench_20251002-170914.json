{ "generated_at": "2025-10-02T21:09:22.605748+00:00", "model": { "name": "transformer", "device": "cpu", "dtype": "torch.float32", "batch_size": 2, "seq_len": 128, "embed_dim": 256, "num_heads": 4, "num_layers": 2 }, "settings": { "runs": 10, "warmup_runs": 3, "backends": [ "eager", "jit", "torch_compile", "onnx" ] }, "backends": { "eager": { "backend": "eager", "compilation": null, "benchmark": { "backend": "eager", "mean_time_ms": 24.723249999988184, "std_time_ms": 2.248217091568642, "min_time_ms": 21.69820000017353, "max_time_ms": 30.158300000039162, "metadata": { "compile_time_s": 0.0 } } }, "jit": { "backend": "jit", "compilation": { "backend": "torchscript", "success": true, "compile_time_s": 0.17530699999952049, "metadata": { "strict": false, "frozen": true, "graph_preview": [ "graph(%self.1 : __torch__.___torch_mangle_39.TinyTransformer,", " %x : Tensor):", " %10 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.layers.0", " %9 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %8 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %7 : int = prim::Constant[value=4](), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %6 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %self.head.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.head.bias : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_weight : Float(768, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_bias : Float(768, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.weight : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.bias : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.weight : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.bias : Float(1024, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.weight : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.bias : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %src : Tensor = aten::_transformer_encoder_layer_fwd(%x, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %input : Tensor = aten::_transformer_encoder_layer_fwd(%src, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.1 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0" ] }, "error": null }, "benchmark": { "backend": "jit", "mean_time_ms": 4.858519999834243, "std_time_ms": 0.5854863649451993, "min_time_ms": 4.242299999532406, "max_time_ms": 5.718099999285187, "metadata": { "compile_time_s": 0.17530699999952049, "strict": false, "frozen": true, "graph_preview": [ "graph(%self.1 : __torch__.___torch_mangle_39.TinyTransformer,", " %x : Tensor):", " %10 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.layers.0", " %9 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %8 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %7 : int = prim::Constant[value=4](), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %6 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %self.head.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.head.bias : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_weight : Float(768, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_bias : Float(768, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.weight : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.bias : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.weight : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.bias : Float(1024, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.weight : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.bias : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()", " %src : Tensor = aten::_transformer_encoder_layer_fwd(%x, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.0 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0", " %input : Tensor = aten::_transformer_encoder_layer_fwd(%src, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.1 # C:\\Users\\sahil\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:902:0" ] } } }, "torch_compile": { "backend": "torch_compile", "compilation": { "backend": "torch.compile", "success": true, "compile_time_s": 0.8979709999985062, "metadata": { "backend": "inductor", "mode": "default", "fullgraph": false, "dynamic": false }, "error": null }, "benchmark": { "backend": "torch_compile", "mean_time_ms": 5.665250000311062, "std_time_ms": 0.3161379646171313, "min_time_ms": 5.114199999297853, "max_time_ms": 6.199000001288368, "metadata": { "compile_time_s": 0.8979709999985062, "backend": "inductor", "mode": "default", "fullgraph": false, "dynamic": false } } }, "onnx": { "backend": "onnx", "compilation": { "backend": "onnx", "success": true, "compile_time_s": 0.31298009999954957, "metadata": { "onnx_path": "C:\\Users\\sahil\\AppData\\Local\\Temp\\chimera_onnx_wj_1y_ig\\model.onnx", "opset": 17, "providers": [ "CPUExecutionProvider" ], "session_type": "onnxruntime" }, "error": null }, "benchmark": { "backend": "onnx", "mean_time_ms": 2.8371399999741698, "std_time_ms": 0.06976370412381123, "min_time_ms": 2.7425000007497147, "max_time_ms": 2.9947000002721325, "metadata": { "compile_time_s": 0.31298009999954957, "onnx_path": "C:\\Users\\sahil\\AppData\\Local\\Temp\\chimera_onnx_wj_1y_ig\\model.onnx", "opset": 17, "providers": [ "CPUExecutionProvider" ], "session_type": "onnxruntime" } } } }
}