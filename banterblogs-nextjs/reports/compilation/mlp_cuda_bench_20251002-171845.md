# Compilation Benchmark Report - Generated: 2025-10-02T21:20:00.971458+00:00
- Model: mlp
- Device: cuda
- DType: torch.float32 | Backend | Success | Compile Time (s) | Mean (ms) | Std (ms) | Min (ms) | Max (ms) | Notes |
| --- | --- | --- | --- | --- | --- | --- | --- |
| eager | yes | 0.0000 | 0.241 | 0.046 | 0.216 | 0.377 | |
| jit | yes | 0.3780 | 0.214 | 0.015 | 0.191 | 0.240 | strict=False; frozen=True; graph_preview=15 lines |
| torch_compile | no | 0.0000 | 0.000 | 0.000 | 0.000 | 0.000 | error=Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo" |
| onnx | yes | 0.3036 | 0.047 | 0.003 | 0.044 | 0.053 | onnx_path=C:\Users\sahil\AppData\Local\Temp\chimera_onnx__efzrtzl\model.onnx; opset=17; providers=CPUExecutionProvider; session_type=onnxruntime |
| tensorrt | yes | 40.5345 | 0.404 | 0.218 | 0.253 | 0.767 | enabled_precisions=torch.float16; workspace_size=268435456 |
