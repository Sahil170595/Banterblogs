{ "generated_at": "2025-10-03T02:43:56.023041+00:00", "model": { "name": "transformer", "device": "cuda", "dtype": "torch.float32", "batch_size": 2, "seq_len": 128, "embed_dim": 256, "num_heads": 4, "num_layers": 2 }, "settings": { "runs": 5, "warmup_runs": 2, "backends": [ "eager", "jit", "torch_compile", "onnx", "tensorrt" ] }, "backends": { "eager": { "backend": "eager", "compilation": null, "benchmark": { "backend": "eager", "mean_time_ms": 1.6945753999607405, "std_time_ms": 0.3674823733413554, "min_time_ms": 1.3551990000451042, "max_time_ms": 2.3569059999317687, "metadata": { "compile_time_s": 0.0 } } }, "jit": { "backend": "jit", "compilation": { "backend": "torchscript", "success": true, "compile_time_s": 0.1551877050001167, "metadata": { "strict": false, "frozen": true, "graph_preview": [ "graph(%self.1 : __torch__.___torch_mangle_39.TinyTransformer,", " %x : Tensor):", " %10 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.layers.0", " %9 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %8 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %7 : int = prim::Constant[value=4](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %6 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %self.head.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.head.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_weight : Float(768, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_bias : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.weight : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.weight : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.bias : Float(1024, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.weight : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %src : Tensor = aten::_transformer_encoder_layer_fwd(%x, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %input : Tensor = aten::_transformer_encoder_layer_fwd(%src, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.1 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0" ] }, "error": null }, "benchmark": { "backend": "jit", "mean_time_ms": 0.3213488000255893, "std_time_ms": 0.02243093736716943, "min_time_ms": 0.2817569998114777, "max_time_ms": 0.34687199968175264, "metadata": { "compile_time_s": 0.1551877050001167, "strict": false, "frozen": true, "graph_preview": [ "graph(%self.1 : __torch__.___torch_mangle_39.TinyTransformer,", " %x : Tensor):", " %10 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.layers.0", " %9 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %8 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %7 : int = prim::Constant[value=4](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %6 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %self.head.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.head.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_weight : Float(768, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.in_proj_bias : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.weight : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.norm2.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.weight : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear1.bias : Float(1024, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.weight : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %self.encoder.layers.0.linear2.bias : Float(256, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()", " %src : Tensor = aten::_transformer_encoder_layer_fwd(%x, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.0 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0", " %input : Tensor = aten::_transformer_encoder_layer_fwd(%src, %6, %7, %self.encoder.layers.0.self_attn.in_proj_weight, %self.encoder.layers.0.self_attn.in_proj_bias, %self.encoder.layers.0.self_attn.out_proj.weight, %self.encoder.layers.0.norm2.bias, %8, %8, %9, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.norm2.weight, %self.encoder.layers.0.norm2.bias, %self.encoder.layers.0.linear1.weight, %self.encoder.layers.0.linear1.bias, %self.encoder.layers.0.linear2.weight, %self.encoder.layers.0.linear2.bias, %10, %10), scope: __module.encoder/__module.encoder.layers.1 # /usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:902:0" ] } } }, "torch_compile": { "backend": "torch_compile", "compilation": { "backend": "torch.compile", "success": true, "compile_time_s": 1.732647917000122, "metadata": { "backend": "inductor", "mode": "default", "fullgraph": false, "dynamic": false }, "error": null }, "benchmark": { "backend": "torch_compile", "mean_time_ms": 0.5865304000508331, "std_time_ms": 0.09980891200505185, "min_time_ms": 0.47344199992949143, "max_time_ms": 0.7602179998684733, "metadata": { "compile_time_s": 1.732647917000122, "backend": "inductor", "mode": "default", "fullgraph": false, "dynamic": false } } }, "onnx": { "backend": "onnx", "compilation": { "backend": "onnx", "success": true, "compile_time_s": 0.2157004189998588, "metadata": { "onnx_path": "/tmp/chimera_onnx_3pk3j8cw/model.onnx", "opset": 17, "providers": [ "CPUExecutionProvider" ], "session_type": "onnxruntime" }, "error": null }, "benchmark": { "backend": "onnx", "mean_time_ms": 3.757966199918883, "std_time_ms": 0.3451548193853488, "min_time_ms": 3.3439449998695636, "max_time_ms": 4.315178000069864, "metadata": { "compile_time_s": 0.2157004189998588, "onnx_path": "/tmp/chimera_onnx_3pk3j8cw/model.onnx", "opset": 17, "providers": [ "CPUExecutionProvider" ], "session_type": "onnxruntime" } } }, "tensorrt": { "backend": "tensorrt", "compilation": { "backend": "tensorrt", "success": false, "compile_time_s": null, "metadata": { "suggestion": "pip install torch-tensorrt -f https://github.com/pytorch/TensorRT/releases" }, "error": "torch_tensorrt is not installed" }, "benchmark": { "backend": "tensorrt", "mean_time_ms": 0.0, "std_time_ms": 0.0, "min_time_ms": 0.0, "max_time_ms": 0.0, "metadata": { "error": "torch_tensorrt is not installed" } } } }
}