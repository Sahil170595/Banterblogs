# Compilation Benchmark Report - Generated: 2025-10-02T21:21:05.012820+00:00
- Model: conv
- Device: cuda
- DType: torch.float32 | Backend | Success | Compile Time (s) | Mean (ms) | Std (ms) | Min (ms) | Max (ms) | Notes |
| --- | --- | --- | --- | --- | --- | --- | --- |
| eager | yes | 0.0000 | 0.154 | 0.007 | 0.141 | 0.161 | |
| jit | yes | 0.0699 | 0.162 | 0.007 | 0.145 | 0.171 | strict=False; frozen=True; graph_preview=19 lines |
| torch_compile | no | 0.0000 | 0.000 | 0.000 | 0.000 | 0.000 | error=Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo" |
| onnx | yes | 0.1425 | 0.774 | 0.080 | 0.682 | 0.914 | onnx_path=C:\Users\sahil\AppData\Local\Temp\chimera_onnx_agu3_1dk\model.onnx; opset=17; providers=CPUExecutionProvider; session_type=onnxruntime |
| tensorrt | yes | 17.1626 | 0.431 | 0.163 | 0.368 | 0.918 | enabled_precisions=torch.float16; workspace_size=268435456 |
